{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47a5a9363e55d322",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Imports and general definitions\n",
    "At the very beginning, we import necessary packages and make definitions regarding the resolution and the endpoint to the api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfec350549787e77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T13:07:12.255804Z",
     "start_time": "2024-06-14T13:07:12.251093Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from rasterio.transform import from_origin\n",
    "from pyproj import CRS\n",
    "from subprocess import Popen\n",
    "import numpy as np\n",
    "import gc\n",
    "import subprocess as sp\n",
    "import xarray as xa\n",
    "import rioxarray as riox\n",
    "import m3u8\n",
    "\n",
    "ENDPOINT = \"https://dunia.esa.int/api/streaming/band_metadata\"\n",
    "ENDPOINT_TILE_BOUNDS = \"https://dunia.esa.int/api/streaming/s2-tiles/utm-bounds\"\n",
    "FPS = 25\n",
    "\n",
    "S2_API = '/{tile_id}/{band}/{year}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad23c1ee-c907-47d2-951d-df6f2708583c",
   "metadata": {},
   "source": [
    "# Setting Parameters\n",
    "\n",
    "Secondly, we set the parameters for the stream selection. We specify the following parameters:\n",
    "- A Sentinel 2 tile id in *tile_id*\n",
    "- The band of the stream. Possible values are B01, B02, B03, B04, B05, B06, B07, B08, B8A, B09, B11, B12\n",
    "- The year of the observed data in *year*, starting from 2019.\n",
    "- A start date and time within that year\n",
    "- An end date and time within that year\n",
    "- A path to store the geotiffs in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1195f5a1ace485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T13:07:12.291020Z",
     "start_time": "2024-06-14T13:07:12.285684Z"
    }
   },
   "outputs": [],
   "source": [
    "# tile\n",
    "tile_id = '29PKR'\n",
    "\n",
    "# band from B01, B02, B03, B04, B05, B06, B07, B08, B8A, B09, B11, B12\n",
    "band = 'B09'\n",
    "\n",
    "if band == 'B01' or band == 'B09':\n",
    "    resolution = 60\n",
    "    width = 1830\n",
    "    height = 1830\n",
    "elif band == 'B05' or band == 'B06' or band == 'B07' or band == 'B8A' or band == 'B11' or band == 'B12':\n",
    "    resolution = 20\n",
    "    width = 5490\n",
    "    height = 5490\n",
    "elif band == 'B02' or band == 'B03' or band == 'B04' or band == 'B08':\n",
    "    resolution = 10\n",
    "    width = 10980\n",
    "    height = 10980\n",
    "else:\n",
    "    raise ValueError(\"Band not supported\")\n",
    "\n",
    "# year from [2019, 2020, 2021, 2022, 2023, 2024, 2025]\n",
    "year = 2025\n",
    "\n",
    "# start_date\n",
    "start_date = datetime(year=year, month=3, day=1, hour=0, minute=0, second=0)\n",
    "\n",
    "# end_date\n",
    "end_date = datetime(year=year, month=3, day=30, hour=23, minute=59, second=59)\n",
    "\n",
    "# path\n",
    "save_path = './geotiffs/s2_bands/'\n",
    "\n",
    "# if the path doesn't exist yet, it is made.\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a00f6face584b",
   "metadata": {},
   "source": [
    "# Accessing the stream\n",
    "To receive an uri to the stream with the right resolution, we send a get request to the dunia api. This also returns metadata for each image in the stream.\n",
    "The metadata contains:\n",
    "- the sensing time of the image\n",
    "- the frame number in the stream\n",
    "- the timing of each frame in the stream\n",
    "- the processing baseline\n",
    "\n",
    "The variables stream_link and frames_metadata will be used in the oncoming steps. \n",
    "\n",
    "Cloud / No data based filtering needs to be applied in combination with the corresponding TCI stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa672ded8bdfe19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T13:07:12.803051Z",
     "start_time": "2024-06-14T13:07:12.330394Z"
    }
   },
   "outputs": [],
   "source": [
    "stream_link = None\n",
    "frames_metadata = None\n",
    "\n",
    "try:\n",
    "    # load streams and metadata\n",
    "    response = requests.get(url=ENDPOINT + S2_API.format(year=year, tile_id=tile_id, band=band),)\n",
    "    print('Response code:', response.status_code)\n",
    "    \n",
    "\n",
    "    # saving the uri of the stream according to the selected resolution.\n",
    "    stream_link = json.loads(response.content)['metadata']['stream_full']\n",
    "\n",
    "    # saving metadata about the images:\n",
    "    #   sensing time (sensing_time)\n",
    "    #   frame number (image_number)\n",
    "    # percentage of non-data in the image (nodata_pixel_percentage)\n",
    "    # cloud coverage (cloudy_pixel_percentage)\n",
    "    # filtering by cloud coverage and non-data percentage needs to be done\n",
    "    # by loading metadata for same time and tile_id.\n",
    "    frames_metadata = json.loads(response.content)['images']\n",
    "except KeyError as e:\n",
    "    print('Stream not found')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc5604ec0ac51c",
   "metadata": {},
   "source": [
    "# Finding the frames\n",
    "With the help of metadata of the whole stream we find segments in range of the specified dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6962c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def round_to_two_decimal_places(value):\n",
    "    return round(value, 2)\n",
    "\n",
    "\n",
    "def find_segments_in_range(playlist_url, start, end):\n",
    "    playlist = m3u8.load(playlist_url) \n",
    "    accumulated_duration = 1.4\n",
    "    segments_in_range = []\n",
    "    frame_rate = 25.0\n",
    "    if start == end:\n",
    "        end = end + 0.01\n",
    "    \n",
    "\n",
    "    for segment in playlist.segments:\n",
    "        segment_start = accumulated_duration\n",
    "        segment_end = round_to_two_decimal_places(accumulated_duration + segment.duration)\n",
    "\n",
    "        if segment_start < end and segment_end > start:\n",
    "            # The index of the first frame of the segment (typically 0)\n",
    "            start_frame_index = round((segment_start - 1.4) * frame_rate)\n",
    "            # The index of the last frame of the segment (typically 3)\n",
    "            end_frame_index = round((segment_end - 1.4) * frame_rate) - 1\n",
    "\n",
    "            relative_start_frame_index = (\n",
    "                round((start - segment_start) * frame_rate)\n",
    "                if start > segment_start\n",
    "                else 0\n",
    "            )\n",
    "\n",
    "            relative_end_frame_index = (\n",
    "                round((end - segment_start) * frame_rate)\n",
    "                if end < segment_end\n",
    "                else round((segment_end - segment_start) * frame_rate) - 1\n",
    "            )\n",
    "\n",
    "            frame_count = round(segment.duration * frame_rate)\n",
    "\n",
    "            segments_in_range.append((\n",
    "                segment.uri,\n",
    "                (segment_start, segment_end),\n",
    "                (start_frame_index, end_frame_index),\n",
    "                (relative_start_frame_index, relative_end_frame_index),\n",
    "                frame_count,\n",
    "                segment.duration,\n",
    "            ))\n",
    "\n",
    "        accumulated_duration = segment_end\n",
    "\n",
    "        if accumulated_duration >= end:\n",
    "            break\n",
    "\n",
    "    return segments_in_range\n",
    "\n",
    "filtered_frames_metadata = []\n",
    "# filtering the metadata according to the selected dates\n",
    "for frame in frames_metadata:\n",
    "    sensing_time = datetime.strptime(frame['sensing_time'], '%Y-%m-%dT%H:%M:%S.%f')\n",
    "    if start_date <= sensing_time <= end_date:\n",
    "        filtered_frames_metadata.append(frame)\n",
    "\n",
    "start_pts = filtered_frames_metadata[0]['pts_time']\n",
    "end_pts = filtered_frames_metadata[-1]['pts_time']\n",
    "\n",
    "segments = find_segments_in_range(stream_link, start_pts, end_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a82a08814ddc4aa",
   "metadata": {},
   "source": [
    "# Transform and CRS\n",
    "\n",
    "Since we want to reference the image geologically, we look up the bounding box of the Sentinel 2 tile and find the crs. The transform to the bounding box and the crs are saved and will be applied in the last step. To get the correct bounding box and epsg the api is contacted again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859424b86b2fd79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T13:07:16.416798Z",
     "start_time": "2024-06-14T13:07:12.815236Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    # load tile bounds and epsg\n",
    "    response = requests.get(url=ENDPOINT_TILE_BOUNDS + f\"/{tile_id}\")\n",
    "    print('Response code:', response.status_code)\n",
    "\n",
    "    response_content = json.loads(response.content.decode('utf-8'))\n",
    "\n",
    "    epsg = response_content['utm']['epsg']\n",
    "    bbox = response_content['utm']['bbox']\n",
    "    \n",
    "except KeyError as e:\n",
    "    print('Tile bounds not found')\n",
    "    \n",
    "\n",
    "# saving the transform and the crs to apply to the extracted frames later\n",
    "transform = from_origin(bbox[0], bbox[3], resolution, resolution)\n",
    "crs = CRS.from_string(epsg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c9dff3c7d6b7fd",
   "metadata": {},
   "source": [
    "# Creating Datasets and extracting to geotiffs\n",
    "\n",
    "With the preparation done, we can finally get to the data. This step is done in one for loop. New images via ffmpeg are loaded and then rescaled with metadata to its actual values.\n",
    " \n",
    "After the image is read into a DataArray the CRS is applied and a transform is made to complete geo-referencing the image.\n",
    "\n",
    "Then we save the image- and geo-information in the DataArray to a geotiff.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0608f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_count = 0\n",
    "\n",
    "print('Loading and converting images:')\n",
    "\n",
    "for segment in segments:\n",
    "    segment_uri = segment[0]\n",
    "    relative_start_frame_index = segment[3][0]\n",
    "    relative_end_frame_index = segment[3][1]\n",
    "    \n",
    "     # Step 1: Stream the .ts file into memory\n",
    "    with requests.get(segment_uri, stream=True) as response:\n",
    "        response.raise_for_status()  # Ensure the request was successful\n",
    "        ts_data = response.content  # Download the entire .ts file into memory\n",
    "\n",
    "        # Step 2: Pass the streamed .ts file to ffmpeg via stdin\n",
    "        for frame_index in range(relative_start_frame_index, relative_end_frame_index + 1):\n",
    "            command = [\n",
    "                'ffmpeg', '-hide_banner',\n",
    "                '-i', 'pipe:0',  # Read input from stdin\n",
    "                '-vf', f'select=eq(n\\\\,{frame_index})',\n",
    "                '-pix_fmt', 'gray16le',\n",
    "                '-f', 'rawvideo',\n",
    "                'pipe:'\n",
    "            ]\n",
    "            \n",
    "            # Run ffmpeg and pass the streamed .ts data via stdin\n",
    "            process = sp.Popen(\n",
    "                command,\n",
    "                stdin=sp.PIPE,\n",
    "                stdout=sp.PIPE,\n",
    "                stderr=sp.PIPE\n",
    "            )\n",
    "            frame_data, error = process.communicate(input=ts_data)\n",
    "\n",
    "            if process.returncode != 0:\n",
    "                raise Exception(f\"Error processing frame {frame_index}: {error.decode('utf-8')}\")\n",
    "                \n",
    "            pix_dtype = np.uint16\n",
    "            bytes_per_pixel_per_band = np.dtype(pix_dtype).itemsize\n",
    "\n",
    "            # Ensure the buffer size matches the expected frame size\n",
    "            expected_size = width * height * bytes_per_pixel_per_band\n",
    "            if len(frame_data) != expected_size:\n",
    "                print(f\"Error: Frame {frame_index} size mismatch. Expected {expected_size}, got {len(frame_data)}\")\n",
    "                break\n",
    "\n",
    "             # Convert the raw frame data to a NumPy array\n",
    "            np_from_buffer = np.frombuffer(frame_data, dtype=pix_dtype)\n",
    "            img_h_w = np_from_buffer.reshape((width, height))  # Assuming a single-band grayscale image\n",
    "            print(\".\", end=\"\")\n",
    "            \n",
    "            current_frame_metadata = filtered_frames_metadata[frame_count]\n",
    "            scale = current_frame_metadata['scale_factor']\n",
    "            offset = current_frame_metadata['add_offset']\n",
    "            \n",
    "            rescaled_img_h_w = ((img_h_w >> 4) * scale + offset).astype(np.uint16)\n",
    "                        \n",
    "            da_image = xa.DataArray(rescaled_img_h_w, dims=['y', 'x'])\n",
    "    \n",
    "            # # Apply the crs of the selected tile to the Dataset\n",
    "            da_image.rio.write_crs(input_crs=crs, inplace=True)\n",
    "            #\n",
    "            # # Apply the transform to the bounding box of the tile to the Dataset\n",
    "            da_image.rio.write_transform(transform=transform, inplace=True)\n",
    "\n",
    "            # your code\n",
    "\n",
    "            \n",
    "            \n",
    "            sensing_time = current_frame_metadata['sensing_time'][:19].replace(':', '').replace('-', '')\n",
    "\n",
    "            # Save the image as a geotiff\n",
    "            tif_name = f\"{save_path}\"\n",
    "            tif_name += f\"T{tile_id}_\"\n",
    "            tif_name += f\"{sensing_time}_\"\n",
    "            tif_name += f\"{current_frame_metadata['baseline']}_\"\n",
    "            tif_name += f\"{band}_\"\n",
    "            tif_name += f\"{resolution}m\"\n",
    "            tif_name += \".tif\"\n",
    "\n",
    "            da_image.rio.to_raster(tif_name)\n",
    "        \n",
    "            frame_count += 1\n",
    "print(\"\")\n",
    "print(\"All done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343bd280-0cfc-4c9a-b712-80807615637f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
