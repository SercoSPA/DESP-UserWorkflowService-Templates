{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47a5a9363e55d322",
   "metadata": {},
   "source": [
    "# Imports and general definitions\n",
    "At the very beginning, we import necessary packages and make definitions regarding the resolution and the endpoint to the api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfec350549787e77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T13:07:12.255804Z",
     "start_time": "2024-06-14T13:07:12.251093Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from rasterio.transform import from_origin\n",
    "from pyproj import CRS\n",
    "from subprocess import Popen\n",
    "import numpy as np\n",
    "import gc\n",
    "import subprocess as sp\n",
    "import xarray as xa\n",
    "import rioxarray as riox\n",
    "\n",
    "s2_resolutions = ['stream_2k', 'stream_4k', 'stream_full']\n",
    "spacial_dim = {'stream_2k': 60, 'stream_4k': 20, 'stream_full': 10}\n",
    "\n",
    "\n",
    "\n",
    "ENDPOINT = \"https://streamer.destine.eu/api/metadata\"\n",
    "S2_API = '/s2/{year}/{tile_id}/10'\n",
    "ENDPOINT_TILE_BOUNDS = \"https://streamer.destine.eu/api/s2-tiles/utm-bounds\"\n",
    "\n",
    "FPS = 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ce35b1-eb4b-4e25-b786-49673a3077a8",
   "metadata": {},
   "source": [
    "# Setting Parameters\n",
    "\n",
    "Secondly, we set the parameters for the stream selection. We specify the following parameters:\n",
    "- A Sentinel 2 tile id in *tile_id*\n",
    "- The resolution of the stream. Possible values are 'stream_2k' (60m per pixel), 'stream_4k' (20m per pixel) and 'stream_full' (10m per pixel)\n",
    "- The year of the observed data in *year*, starting from 2019.\n",
    "- A start date and time within that year\n",
    "- An end date and time within that year\n",
    "- A path to store the geotiffs in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1195f5a1ace485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T13:07:12.291020Z",
     "start_time": "2024-06-14T13:07:12.285684Z"
    }
   },
   "outputs": [],
   "source": [
    "# tile\n",
    "tile_id = '32TPT'\n",
    "\n",
    "# resolution from ['stream_2k', 'stream_4k', 'stream_full']\n",
    "resolution = 'stream_2k'\n",
    "\n",
    "# year from [2019, 2020, 2021, 2022, 2023, 2024]\n",
    "year = 2020\n",
    "\n",
    "# start_date\n",
    "start_date = datetime(year=year, month=4, day=1, hour=0, minute=0, second=0)\n",
    "\n",
    "# end_date\n",
    "end_date = datetime(year=year, month=6, day=30, hour=23, minute=59, second=59)\n",
    "\n",
    "# path\n",
    "save_path = './geotiffs/s2/'\n",
    "\n",
    "# if the path doesn't exist yet, it is made.\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a00f6face584b",
   "metadata": {},
   "source": [
    "# Accessing the stream\n",
    "To receive an uri to the stream with the right resolution, we send a get request to the dunia api. This also returns metadata for each image in the stream.\n",
    "The metadata contains:\n",
    "- cloud coverage in percent\n",
    "- percentage of non-data in the image\n",
    "- the sensing time of the image\n",
    "- the frame number in the stream\n",
    "\n",
    "The variables stream_link and frames_metadata will be used in the oncoming steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa672ded8bdfe19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T13:07:12.803051Z",
     "start_time": "2024-06-14T13:07:12.330394Z"
    }
   },
   "outputs": [],
   "source": [
    "stream_link = None\n",
    "frames_metadata = None\n",
    "\n",
    "try:\n",
    "    # load streams and metadata\n",
    "    response = requests.get(url=ENDPOINT + S2_API.format(year=year, tile_id=tile_id))\n",
    "\n",
    "    # saving the uri of the stream according to the selected resolution.\n",
    "    stream_link = json.loads(response.content)['metadata'][resolution]\n",
    "\n",
    "    # saving metadata about the images:\n",
    "    #   sensing time (sensing_time)\n",
    "    #   frame number (image_number)\n",
    "    # percentage of non-data in the image (nodata_pixel_percentage)\n",
    "    # cloud coverage (cloudy_pixel_percentage)\n",
    "    frames_metadata = json.loads(response.content)['images']\n",
    "except KeyError as e:\n",
    "    print('Stream not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecc5604ec0ac51c",
   "metadata": {},
   "source": [
    "# Finding the starting frame and frame count\n",
    "With the help of metadata of each frame we find the first frame that was taken after the start date we specified in the beginning. Then we count how many frames are contained in the stream, before the end date. The variables start_frame and frame_count are saved for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1748115ee8d501",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T13:07:12.812791Z",
     "start_time": "2024-06-14T13:07:12.806131Z"
    }
   },
   "outputs": [],
   "source": [
    "    start_frame = -1\n",
    "    frame_count = 1\n",
    "\n",
    "    for frame_metadata in frames_metadata:\n",
    "\n",
    "        frame_date = datetime.strptime(frame_metadata['sensing_time'], '%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "        if start_date <= frame_date <= end_date and start_frame == -1:\n",
    "            start_frame = frame_metadata['image_number']\n",
    "        elif frame_date <= end_date and start_frame != -1:\n",
    "            frame_count += 1\n",
    "        elif frame_date > end_date:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a82a08814ddc4aa",
   "metadata": {},
   "source": [
    "# Transform and CRS\n",
    "\n",
    "Since we want to reference the image geologically, we look up the bounding box of the Sentinel 2 tile and find the crs. The transform to the bounding box and the crs are saved and will be applied in the last step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859424b86b2fd79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T13:07:16.416798Z",
     "start_time": "2024-06-14T13:07:12.815236Z"
    }
   },
   "outputs": [],
   "source": [
    "# get dataframe and EPSG projection for tile\n",
    "response = requests.get(url=ENDPOINT_TILE_BOUNDS + f\"/{tile_id}\")\n",
    "\n",
    "response_content = json.loads(response.content.decode(\"utf-8\"))\n",
    "epsg = response_content[\"utm\"][\"epsg\"]\n",
    "bbox = response_content[\"utm\"][\"bbox\"]\n",
    "\n",
    "# saving the transform and the crs to apply to the extracted frames later\n",
    "transform = from_origin(bbox[0], bbox[3], spacial_dim[resolution], spacial_dim[resolution])\n",
    "crs = CRS.from_string(epsg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fd419cd93e234b",
   "metadata": {},
   "source": [
    "# Initializing the Image Loader\n",
    "\n",
    "Up next is a rather technical task that needs to be executed. Feel free to not give this a closer look on your first read (and also any other time as well).\n",
    "\n",
    "Briefly, this code lets us create *image_gen* in the next segment, which loads a new image for every iteration in the loop in the code next segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f26b407cac37834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T13:07:16.425468Z",
     "start_time": "2024-06-14T13:07:16.418349Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_width_height(probe_str: str):\n",
    "    \"\"\"\n",
    "    This function looks through a string to find width and height in pixels\n",
    "\n",
    "    :param probe_str:\n",
    "    :type probe_str: str\n",
    "\n",
    "    :return: - width (int), height (int)\n",
    "    \"\"\"\n",
    "    _width, _height = -1, -1\n",
    "\n",
    "    for element in probe_str.split(', '):\n",
    "        try:\n",
    "            (_width, _height) = list(map(int, element.split('x')))\n",
    "            break\n",
    "        except ValueError as ve:\n",
    "            pass\n",
    "\n",
    "    return _width, _height\n",
    "\n",
    "def width_height_from_std_err(process: Popen):\n",
    "    \"\"\"\n",
    "    This function reads through stderr of a ffmpeg command and\n",
    "    calls find_width_height to find width and height of the images in the stream in pixels.\n",
    "\n",
    "    :param process:\n",
    "    :type process: Popen\n",
    "\n",
    "    :return: - width (int), height (int)\n",
    "    \"\"\"\n",
    "    _width, _height = -1, -1\n",
    "    stderr_iterator = iter(process.stderr.readline, b\"\")\n",
    "\n",
    "    for line in stderr_iterator:\n",
    "        _width, _height = find_width_height(line.decode('utf-8'))\n",
    "        if _width != -1 and _height != -1:\n",
    "            break\n",
    "\n",
    "    return _width, _height\n",
    "\n",
    "def load_images_s2(_process: Popen, _width: int, _height: int):\n",
    "    \"\"\"\n",
    "    This generator reads one sentinel 2 image from a stream on each __next__() and converts it into a\n",
    "    numpy array.\n",
    "\n",
    "    :param _process:\n",
    "    :type _process: Popen\n",
    "    :param _width:\n",
    "    :type _width: int\n",
    "    :param _height:\n",
    "    :type _height: int\n",
    "\n",
    "    :return: - next_image (np.array)\n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "        expected_bands = 3\n",
    "        creating_bands = 3\n",
    "        pix_dtype = np.uint8\n",
    "        bytes_per_pixel_per_band = np.dtype(pix_dtype).itemsize\n",
    "\n",
    "        buffer = _process.stdout.read(_width * _height * bytes_per_pixel_per_band * expected_bands)\n",
    "\n",
    "        if len(buffer) != _width * _height * bytes_per_pixel_per_band * creating_bands:\n",
    "            break\n",
    "\n",
    "        np_from_buffer = np.frombuffer(buffer, pix_dtype)\n",
    "        img_h_w_rgb = np_from_buffer.reshape(_height, _width, creating_bands)\n",
    "        next_image = np.moveaxis(img_h_w_rgb, 2, 0)\n",
    "\n",
    "        del buffer\n",
    "        del np_from_buffer\n",
    "        gc.collect()\n",
    "\n",
    "        yield next_image\n",
    "\n",
    "    _process.stdout.close()\n",
    "    \n",
    "def ffmpeg_init(_stream_link: str, _start_frame: int, _frame_count: int):\n",
    "    \"\"\"\n",
    "    This function initializes an image generator for sentinel 2 (load_images_s2).\n",
    "    For this it accesses the stream (stream_link) seeks to the time of the start_frame\n",
    "    and sets -t to the duration needed to load as many frames as frame_count.\n",
    "\n",
    "\n",
    "    :param _stream_link:\n",
    "    :type _stream_link: str\n",
    "    :param _start_frame:\n",
    "    :type _start_frame: int\n",
    "    :param _frame_count:\n",
    "    :type _frame_count: int\n",
    "\n",
    "    :return: - load_images_s1() or load_images_s2() (generator)\n",
    "    \"\"\"\n",
    "    command = ['ffmpeg', '-hide_banner',\n",
    "               '-ss', f'{start_frame/FPS:.2f}',\n",
    "               '-i', stream_link,\n",
    "               '-pix_fmt', 'rgb24',\n",
    "               '-f', 'rawvideo',\n",
    "               '-t', f'{frame_count / FPS:.2f}',\n",
    "               'pipe:']\n",
    "    \n",
    "    process = sp.Popen(command, stdout=sp.PIPE, stderr=sp.PIPE)\n",
    "    width, height = width_height_from_std_err(process)\n",
    "    process.stderr.close()\n",
    "    \n",
    "    if width == -1 or height == -1:\n",
    "        raise ConnectionError('Stream not found. ')\n",
    "    \n",
    "    return load_images_s2(process, width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c9dff3c7d6b7fd",
   "metadata": {},
   "source": [
    "# Creating Datasets and extracting to geotiffs\n",
    "\n",
    "With the preparation done, we can finally get to the data. This step is done in one for loop as long as image_gen is loading new images. Loop variable frame_no is set to begin at start_frame and set to the frame number of the current image. \n",
    " \n",
    "After the image is read into a DataArray the CRS is applied and a transorm is made to complete geo-referencing the image. Setting up the DataArray is done with line 13.\n",
    "\n",
    "Then we save the image- and geo-information in the DataArray to a geotiff.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e766656a711eca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T13:07:21.073459Z",
     "start_time": "2024-06-14T13:07:16.427010Z"
    }
   },
   "outputs": [],
   "source": [
    "# create the image loader\n",
    "image_gen = ffmpeg_init(stream_link, start_frame, frame_count)\n",
    "\n",
    "for frame_no, image in enumerate(image_gen, start=start_frame):\n",
    "    \n",
    "    current_frame_metadata = frames_metadata[frame_no]\n",
    "    \n",
    "    da_image = xa.DataArray(image, dims=['rgb', 'y', 'x'])\n",
    "\n",
    "    # # Apply the crs of the selected tile to the Dataset\n",
    "    da_image.rio.write_crs(input_crs=crs, inplace=True)\n",
    "    #\n",
    "    # # Apply the transform to the bounding box of the tile to the Dataset\n",
    "    da_image.rio.write_transform(transform=transform, inplace=True)\n",
    "\n",
    "    # your code\n",
    "\n",
    "    # Save the image as a geotiff\n",
    "    tif_name = f\"{save_path}\"\n",
    "    tif_name += f\"{tile_id}_\"\n",
    "    tif_name += f\"{resolution}_\"\n",
    "    tif_name += f\"{current_frame_metadata['sensing_time']}\".replace(':', '').replace('-', '')\n",
    "    tif_name += \".tiff\"\n",
    "\n",
    "    print(tif_name)\n",
    "\n",
    "    da_image.rio.to_raster(tif_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a81d85adfe0da9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T13:07:21.077757Z",
     "start_time": "2024-06-14T13:07:21.074583Z"
    }
   },
   "outputs": [],
   "source": [
    "print('All done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
